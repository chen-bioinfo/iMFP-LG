{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_data(filepath, save_path):\n",
    "    \"\"\"\n",
    "    Convert fasta(.txt) files to numpy files(.npy)\n",
    "    The numpy file saves the train and test data in the format of a dictionary, \n",
    "    where the key value is a sequence, and the value is the label of the sequence\n",
    "    format: {seq1: label1, seq2: label2, ....}   seq(str), label(numpy.array)\n",
    "    param: filepath: The path of the fasta file that saves the training and testing data\n",
    "           save_path:  Processed numpy file path\n",
    "    return: None\n",
    "    \"\"\"\n",
    "    seq_label_dict = dict()\n",
    "    with open(filepath) as f:\n",
    "        for raw in f.readlines():\n",
    "            if raw[0] == '>':\n",
    "                label = raw[1:-1]\n",
    "                label = [int(l) for l in label]\n",
    "                label = np.array(label)\n",
    "            else:\n",
    "                if raw[-1] == '\\n':\n",
    "                    seq = raw[:-1]\n",
    "                else:\n",
    "                    seq = raw\n",
    "                seq_label_dict[seq] = label\n",
    "    np.save(save_path, seq_label_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\")))\n",
    "# filepath\n",
    "train_data_path = os.path.join(data_dir,'MFTP', 'train.txt')   # MFTP\n",
    "test_data_path = os.path.join(data_dir,'MFTP', 'test.txt')\n",
    "# save_path\n",
    "process_train_data_path = os.path.join(data_dir,'MFTP', 'train_data.npy')   # MFTP\n",
    "process_test_data_path = os.path.join(data_dir,'MFTP', 'test_data.npy')\n",
    "\n",
    "process_data(train_data_path, process_train_data_path)\n",
    "process_data(test_data_path, process_test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CPP': 366, 'AIP': 1624, 'ABP': 1735, 'AHP': 758, 'ACP': 850, 'AFP': 1079, 'BIP': 274, 'AVP': 568, 'THP': 531, 'QSP': 171, 'ACVP': 98, 'AAP': 115, 'ADP': 400, 'SBP': 89, 'AMRSAP': 147, 'AEP': 48, 'APP': 218, 'DPPIP': 250, 'AHIVP': 82, 'ATP': 182, 'BBP': 92}\n",
      "{'AFP': 273, 'ABP': 419, 'BIP': 61, 'AHP': 190, 'AMRSAP': 21, 'AAP': 18, 'ACP': 193, 'AVP': 143, 'AIP': 425, 'THP': 120, 'QSP': 49, 'AHIVP': 19, 'CPP': 93, 'ACVP': 28, 'ADP': 109, 'APP': 61, 'DPPIP': 63, 'BBP': 25, 'ATP': 60, 'SBP': 15, 'AEP': 10}\n",
      "CPP 459 366 / 93\n",
      "AIP 2049 1624 / 425\n",
      "ABP 2154 1735 / 419\n",
      "AHP 948 758 / 190\n",
      "ACP 1043 850 / 193\n",
      "AFP 1352 1079 / 273\n",
      "BIP 335 274 / 61\n",
      "AVP 711 568 / 143\n",
      "THP 651 531 / 120\n",
      "QSP 220 171 / 49\n",
      "ACVP 126 98 / 28\n",
      "AAP 133 115 / 18\n",
      "ADP 509 400 / 109\n",
      "SBP 104 89 / 15\n",
      "AMRSAP 168 147 / 21\n",
      "AEP 58 48 / 10\n",
      "APP 279 218 / 61\n",
      "DPPIP 313 250 / 63\n",
      "AHIVP 101 82 / 19\n",
      "ATP 242 182 / 60\n",
      "BBP 117 92 / 25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "peptide_type = ['AAP', 'ABP', 'ACP', 'ACVP', 'ADP', 'AEP', 'AFP', 'AHIVP', 'AHP', 'AIP', 'AMRSAP', 'APP', 'ATP',\n",
    "             'AVP',\n",
    "             'BBP', 'BIP',\n",
    "             'CPP', 'DPPIP',\n",
    "             'QSP', 'SBP', 'THP']\n",
    "train_data_npy = np.load(process_train_data_path, allow_pickle=True).item()\n",
    "test_data_npy = np.load(process_test_data_path, allow_pickle=True).item()\n",
    "\n",
    "def count_peptide_num(data_npy, peptide_type):\n",
    "    peptide_num = dict()\n",
    "    for seq in data_npy.keys():\n",
    "        label = data_npy[seq]\n",
    "        for i in range(len(label)):\n",
    "            if label[i] == 1:\n",
    "                if peptide_type[i] not in peptide_num.keys():\n",
    "                    peptide_num[peptide_type[i]] = 1\n",
    "                else:\n",
    "                    peptide_num[peptide_type[i]] += 1\n",
    "    \n",
    "    return peptide_num\n",
    "\n",
    "train_peptide_num = count_peptide_num(train_data_npy, peptide_type)\n",
    "test_peptide_num = count_peptide_num(test_data_npy, peptide_type)\n",
    "print(train_peptide_num)\n",
    "print(test_peptide_num)\n",
    "for key in train_peptide_num.keys():\n",
    "    print(key, train_peptide_num[key] + test_peptide_num[key], train_peptide_num[key],\"/\", test_peptide_num[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d63231a3689373e504d752b656abbebf4c65d1a53960ba549fb28b84ab7f5d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
